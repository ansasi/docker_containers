---
networks:
  proxy:
    external: true

services:
  openwebui:
    container_name: openwebui
    image: ghcr.io/open-webui/open-webui:v0.6.18 # Use ghcr.io/open-webui/open-webui:cuda for NVIDIA GPUs
    # # Use this for NVIDIA GPUs
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]
    environment:
      OLLAMA_BASE_URL: ${OLLAMA_DOMAIN:-http://ollama:11434}
      WEBUI_URL: http://localhost:3003 # openwebui.${DOMAIN}
    volumes:
      - ${WORKDIR}/data:/app/backend/data
    ports:
      - ${OPEN_WEBUI_PORT:-3003}:8080
    labels:
      - traefik.enable=true
      - traefik.docker.network=proxy
      - traefik.http.routers.openwebui.entrypoints=http
      - traefik.http.routers.openwebui.rule=Host(`openwebui.${DOMAIN}`)
      - traefik.http.routers.openwebui-secure.entrypoints=https
      - traefik.http.routers.openwebui-secure.rule=Host(`openwebui.${DOMAIN}`)
      - traefik.http.routers.openwebui-secure.tls=true
      - traefik.http.routers.openwebui-secure.tls.certresolver=cloudflare
      - traefik.http.routers.openwebui-secure.service=openwebui
      - traefik.http.services.openwebui.loadbalancer.server.port=8080
    networks:
      - proxy
    restart: unless-stopped
    security_opt:
      - no-new-privileges:true